{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sally\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import backend as BK\n",
    "import cv2\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.io.wavfile import write\n",
    "import scipy.io as sio\n",
    "from collections import OrderedDict\n",
    "import random \n",
    "random.seed(100)\n",
    "import fnmatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "CNN input path is D:/Mrs_backup/speech_test/cnn/face/s23/\n",
      "face_doc path is D:/Mrs_backup/speech_test/cnn/face/s23\n",
      "audio path is D:/Mrs_backup/speech_test/AudSpecs/s23\n",
      "autoencoder path is: D:/Mrs_backup/speech_test/autoencoder/s23_trainModel/\n",
      "integrate path is: D:/Mrs_backup/speech_test/cnn/input/s23/\n"
     ]
    }
   ],
   "source": [
    "speaker = 's23'\n",
    "\n",
    "frame_width =128\n",
    "frame_height =128\n",
    "num_frame = 75\n",
    "slice_length =5\n",
    "num_slices=15\n",
    "print(num_slices)\n",
    "\n",
    "CNN_path = 'D:/Mrs_backup/speech_test/cnn/face/'+ speaker + '/'\n",
    "face_doc = 'D:/Mrs_backup/speech_test/cnn/face/'+ speaker + ''\n",
    "audio_path = 'D:/Mrs_backup/speech_test/AudSpecs/'+ speaker+ ''\n",
    "autoencoder_path= 'D:/Mrs_backup/speech_test/autoencoder/'+ speaker + '_trainModel/'\n",
    "integrate_data_path ='D:/Mrs_backup/speech_test/cnn/input/'+ speaker + '/'\n",
    "if not os.path.exists(integrate_data_path):\n",
    "    os.mkdir(integrate_data_path)\n",
    "    \n",
    "print('CNN input path is '+ CNN_path)\n",
    "print('face_doc path is '+ face_doc)\n",
    "print('audio path is '+ audio_path)\n",
    "print('autoencoder path is: '+autoencoder_path)\n",
    "print('integrate path is: '+integrate_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Define functions for video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define load_video_3D function and Cap frames (75) frame width and frame height (128)\n",
    "def load_video_3D(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = num_frame\n",
    "    frameHeight=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n",
    "    frameWidth=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH ))\n",
    "    \n",
    "    buf =np.empty((frameHeight, frameWidth, frameCount), np.dtype('float32'))\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    \n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame=frame.astype('float32')\n",
    "        frame = frame-np.amin(frame)\n",
    "        frame = frame/np.amax(frame)\n",
    "        buf[:,:,fc]=frame\n",
    "        fc += 1\n",
    "    cap.release()\n",
    "    return buf\n",
    "\n",
    "# Define diff function to add 3 time-derivative channels\n",
    "def diff(buf_input):\n",
    "    buf_input=np.pad(buf_input,((0,0),(0,0),(1,0)),'edge')\n",
    "    buf_output=np.diff(buf_input,axis=2)\n",
    "    return buf_output\n",
    "\n",
    "# Define slice_video_3D function to divide into 15 non-overlap slices each of length 5\n",
    "def slice_video_3D(video):\n",
    "    video_output =np.empty((num_slices,3,frame_height,frame_width,slice_length), np.dtype('float32'))\n",
    "    \n",
    "    start=0\n",
    "    for i in range(0,num_slices):\n",
    "        video_output[i,:,:,:,:]=video[:,:,:,start:start+slice_length]\n",
    "        start+=slice_length\n",
    "    return video_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbad1s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/000.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbad2p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/001.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbad3a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/002.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbadzn.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/003.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaj4n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/004.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaj5s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/005.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaj6p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/006.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaj7a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/007.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbap8n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/008.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbap9s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/009.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaq1a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/010.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbaqzp.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/011.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbax2n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/012.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbax3s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/013.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbax4p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/014.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbax5a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/015.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbd4n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/016.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbd5s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/017.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbd6p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/018.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbd7a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/019.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbj8n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/020.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbj9s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/021.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbk1a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/022.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbkzp.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/023.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbq2n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/024.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbq3s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/025.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbq4p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/026.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbq5a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/027.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbx6n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/028.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbx7s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/029.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbx8p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/030.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbbx9a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/031.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbic6n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/032.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbic7s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/033.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbic8p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/034.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbic9a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/035.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbij1s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/036.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbij2p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/037.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbij3a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/038.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbijzn.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/039.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbip4n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/040.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbip5s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/041.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbip6p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/042.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbip7a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/043.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbiv8n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/044.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbiv9s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/045.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbix1a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/046.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbixzp.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/047.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwd8n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/048.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwd9s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/049.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwe1a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/050.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwezp.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/051.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwk2n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/052.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwk3s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/053.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwk4p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/054.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwk5a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/055.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwq6n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/056.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwq7s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/057.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwq8p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/058.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwq9a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/059.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwy1s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/060.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwy2p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/061.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwy3a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/062.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bbwyzn.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/063.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgae8n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/064.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgae9s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/065.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgaf1a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/066.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgafzp.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/067.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgal2n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/068.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgal3s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/069.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgal4p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/070.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgal5a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/071.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgar6n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/072.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgar7s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/073.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgar8p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/074.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgar9a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/075.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgaz1s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/076.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgaz2p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/077.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgaz3a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/078.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgazzn.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/079.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbf2n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/080.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbf3s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/081.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbf4p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/082.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbf5a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/083.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbl6n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/084.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbl7s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/085.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbl8p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/086.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbl9a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/087.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbs1s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/088.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbs2p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/089.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbs3a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/090.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbszn.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/091.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbz4n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/092.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbz5s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/093.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbz6p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/094.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgbz7a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/095.avi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgie4n.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/096.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgie5s.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/097.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgie6p.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/098.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/bgie7a.avi\n",
      "D:/Mrs_backup/speech_test/cnn/face/s23/099.avi\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for filename in os.listdir(CNN_path): \n",
    "    src =CNN_path+ filename \n",
    "    print(src)\n",
    "    format_num1=\"{number:03}\".format(number=j)\n",
    "    dst =CNN_path + str(format_num1)+'.avi'\n",
    "    print(dst)\n",
    "    os.rename(src, dst)\n",
    "    j=j+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#Create a text file for visual input path\n",
    "file = open(face_doc +'_valid_videos.txt','w')   \n",
    "file.close()\n",
    "\n",
    "# Get the amount of files in face folder \n",
    "numfiles=len(fnmatch.filter(os.listdir(CNN_path), '*.avi'))\n",
    "print(numfiles)\n",
    "\n",
    "for j in range(0,numfiles):\n",
    "    format_num=\"{number:03}\".format(number=j)\n",
    "   \n",
    "    with open(face_doc +'_valid_videos.txt', 'a') as file:\n",
    "        file.write(CNN_path+str(format_num)+'.avi\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Video frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "10/100\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "20/100\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30/100\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "40/100\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50/100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "60/100\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "70/100\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "80/100\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "90/100\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Video slices shape:(1500, 3, 128, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "# Open the text file of auditory spectrogram input path \n",
    "text_file = open(face_doc +'_valid_videos.txt', 'r')\n",
    "\n",
    "# Load each line of the text file\n",
    "lines = text_file.read().split('\\n')\n",
    "index_shuf=list(range(len(lines)))\n",
    "lines_shuf=[]\n",
    "for i in index_shuf:\n",
    "    lines_shuf.append(lines[i])\n",
    "    \n",
    "#Save a dictionary of names and arrays into a MATLAB-style .mat file\n",
    "sio.savemat('index_s1_2_4_29.mat', mdict={'lines_shuf':lines_shuf}) \n",
    "#print(lines_shuf)\n",
    "\n",
    "# Get the number of videos\n",
    "num_videos=len(lines)\n",
    "\n",
    "# Define the shape of the video_input [10*15,3,128,128,5]\n",
    "video_input =np.empty((num_videos*(num_slices),3,int(frame_height),int(frame_width),int(slice_length)), np.dtype('float32'))\n",
    "\n",
    "speaker_id=OrderedDict()\n",
    "\n",
    "# Get video data\n",
    "i=0\n",
    "for row in lines_shuf:\n",
    "    #print(i)\n",
    "    this_id=row.split('/')[6]\n",
    "    if this_id in speaker_id:\n",
    "        speaker_id[this_id]+=1\n",
    "    else:\n",
    "        speaker_id[this_id]=1\n",
    "    \n",
    "    # Call load_video_3D function to cap frames (75) frame width and frame height (128) from the path\n",
    "    tmp0=load_video_3D(row)\n",
    "    \n",
    "    # Call diff function to add 3 time-derivative channels\n",
    "    diff_video=np.empty((3,tmp0.shape[0],tmp0.shape[1],tmp0.shape[2]))\n",
    "    diff_video[0,:,:,:]=tmp0\n",
    "    diff_video[1,:,:,:]=diff(tmp0)\n",
    "    diff_video[2,:,:,:]=diff(diff_video[1,:,:,:])\n",
    "    \n",
    "    #print(diff_video.shape)\n",
    "    # Call slice_video_3D function\n",
    "    data_vid=slice_video_3D(diff_video)\n",
    "    \n",
    "    # Add total number of slices \n",
    "    video_input[i*(num_slices):(i+1)*(num_slices),:,:,:,:]=data_vid[:,:,:,:,:]\n",
    "    \n",
    "    i+=1\n",
    "    print(i)\n",
    "    if i>=num_videos:\n",
    "        break\n",
    "    if i%10==0:\n",
    "        print(str(i)+'/'+str(num_videos))\n",
    "print('Video slices shape:'+str(video_input.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Define functions for audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define slice_audio_spec function to to divide into 15 non-overlap slices each of length 26\n",
    "def slice_audio_spec(audio_spec):\n",
    "    global AUDIO_LENGTH\n",
    "    window_size=int(AUDIO_LENGTH/num_slices) #from time to number of audio index \n",
    "    #print(window_size)\n",
    "    audio_output =np.empty((num_slices,audio_spec.shape[0],window_size), np.dtype('float32'))\n",
    "    start=0\n",
    "    for i in range(0,num_slices):\n",
    "        audio_output[i,:,:]=audio_spec[:,start:start+window_size]\n",
    "        start+=window_size\n",
    "        if start>AUDIO_LENGTH-window_size:\n",
    "            break\n",
    "    #print(audio_output.shape)\n",
    "    #print(audio_output[1,:,1])\n",
    "    return audio_output\n",
    "\n",
    "# Define get activations function # Extract the 32-bin bottleneck features as target for the main network\n",
    "def get_activations(model, layer_in, layer_out, X_batch):\n",
    "    get_activations = BK.function([model.layers[layer_in].input, BK.learning_phase()], [model.layers[layer_out].output])\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations\n",
    "\n",
    "#Define padding function\n",
    "def get_padded_spec(data):\n",
    "    \n",
    "    # Compress the spectrogram by raising to the power 1/3\n",
    "    #print(data[1:3,1])\n",
    "    data=np.power(data,.3)\n",
    "    #print(data[1,370])\n",
    "    \n",
    "    # Get the video length\n",
    "    t=data.shape[1]\n",
    "   \n",
    "    # Get the number of pads\n",
    "    num_pads=int((2*num_slices)-(t%(2*num_slices)))\n",
    "    #print(num_pads)\n",
    "    \n",
    "    # Add padding to the video length\n",
    "    padded_data=np.pad(data,((0,0),(0,num_pads)),'reflect')\n",
    "    #print(padded_data.shape)\n",
    "\n",
    "    return padded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Load autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading autoencoder model...\n"
     ]
    }
   ],
   "source": [
    "# Define cost function [mean squared error + correlation loss]\n",
    "def corr2_mse_loss(a,b):\n",
    "    a = BK.tf.subtract(a, BK.tf.reduce_mean(a))\n",
    "    b = BK.tf.subtract(b, BK.tf.reduce_mean(b))\n",
    "    tmp1 = BK.tf.reduce_sum(BK.tf.multiply(a,a))\n",
    "    tmp2 = BK.tf.reduce_sum(BK.tf.multiply(b,b))\n",
    "    tmp3 = BK.tf.sqrt(BK.tf.multiply(tmp1,tmp2))\n",
    "    tmp4 = BK.tf.reduce_sum(BK.tf.multiply(a,b))\n",
    "    r = -BK.tf.divide(tmp4,tmp3)\n",
    "    m=BK.tf.reduce_mean(BK.tf.square(BK.tf.subtract(a, b)))\n",
    "    rm=BK.tf.add(r,m)\n",
    "    return rm\n",
    "\n",
    "# Load autoencoder model\n",
    "print('Loading autoencoder model...')\n",
    "config = BK.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = BK.tf.Session(config=config)\n",
    "model=load_model(autoencoder_path+'autoencoder.h5',custom_objects={'corr2_mse_loss': corr2_mse_loss})\n",
    "model.load_weights(autoencoder_path+'autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#Create a text file for visual input path\n",
    "file = open(audio_path +'_valid_aud_specs.txt','w')   \n",
    "file.close()\n",
    "\n",
    "# Get the amount of files in face folder \n",
    "numfiles=len(fnmatch.filter(os.listdir(audio_path+'/'), '*.mat'))\n",
    "print(numfiles)\n",
    "\n",
    "for j in range(0,numfiles):\n",
    "    format_num=\"{number:03}\".format(number=j)\n",
    "   \n",
    "    with open(audio_path +'_valid_aud_specs.txt', 'a') as file:\n",
    "        file.write(audio_path+'/'+str(format_num)+'.mat\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7)Audio feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio slices shape:(1500, 32, 26)\n",
      "10/100\n",
      "20/100\n",
      "30/100\n",
      "40/100\n",
      "50/100\n",
      "60/100\n",
      "70/100\n",
      "80/100\n",
      "90/100\n",
      "Audio slices shape:(1500, 32, 26)\n",
      "Target features to network shape:(1500, 832)\n",
      "OrderedDict([('000.avi', 1), ('001.avi', 1), ('002.avi', 1), ('003.avi', 1), ('004.avi', 1), ('005.avi', 1), ('006.avi', 1), ('007.avi', 1), ('008.avi', 1), ('009.avi', 1), ('010.avi', 1), ('011.avi', 1), ('012.avi', 1), ('013.avi', 1), ('014.avi', 1), ('015.avi', 1), ('016.avi', 1), ('017.avi', 1), ('018.avi', 1), ('019.avi', 1), ('020.avi', 1), ('021.avi', 1), ('022.avi', 1), ('023.avi', 1), ('024.avi', 1), ('025.avi', 1), ('026.avi', 1), ('027.avi', 1), ('028.avi', 1), ('029.avi', 1), ('030.avi', 1), ('031.avi', 1), ('032.avi', 1), ('033.avi', 1), ('034.avi', 1), ('035.avi', 1), ('036.avi', 1), ('037.avi', 1), ('038.avi', 1), ('039.avi', 1), ('040.avi', 1), ('041.avi', 1), ('042.avi', 1), ('043.avi', 1), ('044.avi', 1), ('045.avi', 1), ('046.avi', 1), ('047.avi', 1), ('048.avi', 1), ('049.avi', 1), ('050.avi', 1), ('051.avi', 1), ('052.avi', 1), ('053.avi', 1), ('054.avi', 1), ('055.avi', 1), ('056.avi', 1), ('057.avi', 1), ('058.avi', 1), ('059.avi', 1), ('060.avi', 1), ('061.avi', 1), ('062.avi', 1), ('063.avi', 1), ('064.avi', 1), ('065.avi', 1), ('066.avi', 1), ('067.avi', 1), ('068.avi', 1), ('069.avi', 1), ('070.avi', 1), ('071.avi', 1), ('072.avi', 1), ('073.avi', 1), ('074.avi', 1), ('075.avi', 1), ('076.avi', 1), ('077.avi', 1), ('078.avi', 1), ('079.avi', 1), ('080.avi', 1), ('081.avi', 1), ('082.avi', 1), ('083.avi', 1), ('084.avi', 1), ('085.avi', 1), ('086.avi', 1), ('087.avi', 1), ('088.avi', 1), ('089.avi', 1), ('090.avi', 1), ('091.avi', 1), ('092.avi', 1), ('093.avi', 1), ('094.avi', 1), ('095.avi', 1), ('096.avi', 1), ('097.avi', 1), ('098.avi', 1), ('099.avi', 1)])\n"
     ]
    }
   ],
   "source": [
    "# Open the text file of auditory spectrogram input path \n",
    "text_file = open(audio_path +'_valid_aud_specs.txt','r')\n",
    "\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "lines_shuf=[]\n",
    "for i in index_shuf:\n",
    "    lines_shuf.append(lines[i])\n",
    "\n",
    "# Get the number of audios\n",
    "num_audios=len(lines)\n",
    "\n",
    "# Get data shape \n",
    "#print(lines[0])\n",
    "mat=sio.loadmat(lines[0])\n",
    "data = mat['y'].T[:,2:]\n",
    "\n",
    "# get_padded_spec function to get the shape after padding data\n",
    "padded_data=get_padded_spec(data=data)\n",
    "global AUDIO_LENGTH\n",
    "AUDIO_LENGTH=padded_data.shape[1]\n",
    "\n",
    "# Call get_activations function to get the shape after bottleneck features\n",
    "bottleneck=get_activations(model, 0, 12, padded_data.T)\n",
    "bottleneck=bottleneck[0].T\n",
    "\n",
    "# Get the total shape of audio_input variable\n",
    "audio_input =np.empty((num_audios*(num_slices),bottleneck.shape[0],int(AUDIO_LENGTH/num_slices)), np.dtype('float32'))\n",
    "print(\"Audio slices shape:\" + str(audio_input.shape))\n",
    "\n",
    "tmp =np.zeros((AUDIO_LENGTH), np.dtype('float32'))\n",
    "\n",
    "\n",
    "i=0\n",
    "for row in lines_shuf:\n",
    "    \n",
    "    # Load data from the path\n",
    "    mat=sio.loadmat(row)\n",
    "    \n",
    "    # Read data from the second feature\n",
    "    data = mat['y'].T[:,2:]\n",
    "    #print(data[:,1])\n",
    "    \n",
    "    # Call get_padded_spec function: \n",
    "    # (1). Compress the spectrogram by raising to the power 1/3 \n",
    "    # (2). Add padding to the video length \n",
    "    padded_data=get_padded_spec(data=data)\n",
    "   \n",
    "    \n",
    "    # Call get_activations function to get the bottleneck feature from autoencoder model \n",
    "    # Encoder auditory spectrogram\n",
    "    #print(padded_data.T.shape)\n",
    "    #print(padded_data.T[1,1:10])\n",
    "    bottleneck=get_activations(model, 0, 12, padded_data.T)\n",
    "    #print(bottleneck[0].shape)\n",
    "    #print(bottleneck[0][1,:])\n",
    "    \n",
    "    #Transpose bottleneck[0] varaible\n",
    "    bottleneck=bottleneck[0].T\n",
    "       \n",
    "    # Call slice_audio_spec function to divide into 15 non-overlap audio slices each of length [390/15] 26\n",
    "    data=slice_audio_spec(bottleneck)\n",
    "    #print(data.shape)\n",
    "    \n",
    "    #Get the total audio slices\n",
    "    audio_input[i*(num_slices):(i+1)*(num_slices),:,:]=data[:,:,:]\n",
    "    i+=1\n",
    "    if i>=num_audios:\n",
    "        break\n",
    "    if i%10==0:\n",
    "        print(str(i)+'/'+str(num_audios))\n",
    "\n",
    "audio_output=np.reshape(audio_input,(audio_input.shape[0],audio_input.shape[1]*audio_input.shape[2]))\n",
    "print('Audio slices shape:'+str(audio_input.shape))\n",
    "print('Target features to network shape:'+str(audio_output.shape))\n",
    "\n",
    "print(speaker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Data_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data part1...\n",
      "Saving test data\n",
      "0 to 15\n",
      "Saving data part2...\n",
      "Saving test data\n",
      "15 to 30\n",
      "Saving data part3...\n",
      "Saving test data\n",
      "30 to 45\n",
      "Saving data part4...\n",
      "Saving test data\n",
      "45 to 60\n",
      "Saving data part5...\n",
      "Saving test data\n",
      "60 to 75\n",
      "Saving data part6...\n",
      "Saving test data\n",
      "75 to 90\n",
      "Saving data part7...\n",
      "Saving test data\n",
      "90 to 105\n",
      "Saving data part8...\n",
      "Saving test data\n",
      "105 to 120\n",
      "Saving data part9...\n",
      "Saving test data\n",
      "120 to 135\n",
      "Saving data part10...\n",
      "Saving test data\n",
      "135 to 150\n",
      "Saving data part11...\n",
      "Saving test data\n",
      "150 to 165\n",
      "Saving data part12...\n",
      "Saving test data\n",
      "165 to 180\n",
      "Saving data part13...\n",
      "Saving test data\n",
      "180 to 195\n",
      "Saving data part14...\n",
      "Saving test data\n",
      "195 to 210\n",
      "Saving data part15...\n",
      "Saving test data\n",
      "210 to 225\n",
      "Saving data part16...\n",
      "Saving test data\n",
      "225 to 240\n",
      "Saving data part17...\n",
      "Saving test data\n",
      "240 to 255\n",
      "Saving data part18...\n",
      "Saving test data\n",
      "255 to 270\n",
      "Saving data part19...\n",
      "Saving test data\n",
      "270 to 285\n",
      "Saving data part20...\n",
      "Saving test data\n",
      "285 to 300\n",
      "Saving data part21...\n",
      "Saving test data\n",
      "300 to 315\n",
      "Saving data part22...\n",
      "Saving test data\n",
      "315 to 330\n",
      "Saving data part23...\n",
      "Saving test data\n",
      "330 to 345\n",
      "Saving data part24...\n",
      "Saving test data\n",
      "345 to 360\n",
      "Saving data part25...\n",
      "Saving test data\n",
      "360 to 375\n",
      "Saving data part26...\n",
      "Saving test data\n",
      "375 to 390\n",
      "Saving data part27...\n",
      "Saving test data\n",
      "390 to 405\n",
      "Saving data part28...\n",
      "Saving test data\n",
      "405 to 420\n",
      "Saving data part29...\n",
      "Saving test data\n",
      "420 to 435\n",
      "Saving data part30...\n",
      "Saving test data\n",
      "435 to 450\n",
      "Saving data part31...\n",
      "Saving test data\n",
      "450 to 465\n",
      "Saving data part32...\n",
      "Saving test data\n",
      "465 to 480\n",
      "Saving data part33...\n",
      "Saving test data\n",
      "480 to 495\n",
      "Saving data part34...\n",
      "Saving test data\n",
      "495 to 510\n",
      "Saving data part35...\n",
      "Saving test data\n",
      "510 to 525\n",
      "Saving data part36...\n",
      "Saving test data\n",
      "525 to 540\n",
      "Saving data part37...\n",
      "Saving test data\n",
      "540 to 555\n",
      "Saving data part38...\n",
      "Saving test data\n",
      "555 to 570\n",
      "Saving data part39...\n",
      "Saving test data\n",
      "570 to 585\n",
      "Saving data part40...\n",
      "Saving test data\n",
      "585 to 600\n",
      "Saving data part41...\n",
      "Saving test data\n",
      "600 to 615\n",
      "Saving data part42...\n",
      "Saving test data\n",
      "615 to 630\n",
      "Saving data part43...\n",
      "Saving test data\n",
      "630 to 645\n",
      "Saving data part44...\n",
      "Saving test data\n",
      "645 to 660\n",
      "Saving data part45...\n",
      "Saving test data\n",
      "660 to 675\n",
      "Saving data part46...\n",
      "Saving test data\n",
      "675 to 690\n",
      "Saving data part47...\n",
      "Saving test data\n",
      "690 to 705\n",
      "Saving data part48...\n",
      "Saving test data\n",
      "705 to 720\n",
      "Saving data part49...\n",
      "Saving test data\n",
      "720 to 735\n",
      "Saving data part50...\n",
      "Saving test data\n",
      "735 to 750\n",
      "Saving data part51...\n",
      "Saving test data\n",
      "750 to 765\n",
      "Saving data part52...\n",
      "Saving test data\n",
      "765 to 780\n",
      "Saving data part53...\n",
      "Saving test data\n",
      "780 to 795\n",
      "Saving data part54...\n",
      "Saving test data\n",
      "795 to 810\n",
      "Saving data part55...\n",
      "Saving test data\n",
      "810 to 825\n",
      "Saving data part56...\n",
      "Saving test data\n",
      "825 to 840\n",
      "Saving data part57...\n",
      "Saving test data\n",
      "840 to 855\n",
      "Saving data part58...\n",
      "Saving test data\n",
      "855 to 870\n",
      "Saving data part59...\n",
      "Saving test data\n",
      "870 to 885\n",
      "Saving data part60...\n",
      "Saving test data\n",
      "885 to 900\n",
      "Saving data part61...\n",
      "Saving test data\n",
      "900 to 915\n",
      "Saving data part62...\n",
      "Saving test data\n",
      "915 to 930\n",
      "Saving data part63...\n",
      "Saving test data\n",
      "930 to 945\n",
      "Saving data part64...\n",
      "Saving test data\n",
      "945 to 960\n",
      "Saving data part65...\n",
      "Saving test data\n",
      "960 to 975\n",
      "Saving data part66...\n",
      "Saving test data\n",
      "975 to 990\n",
      "Saving data part67...\n",
      "Saving test data\n",
      "990 to 1005\n",
      "Saving data part68...\n",
      "Saving test data\n",
      "1005 to 1020\n",
      "Saving data part69...\n",
      "Saving test data\n",
      "1020 to 1035\n",
      "Saving data part70...\n",
      "Saving test data\n",
      "1035 to 1050\n",
      "Saving data part71...\n",
      "Saving test data\n",
      "1050 to 1065\n",
      "Saving data part72...\n",
      "Saving test data\n",
      "1065 to 1080\n",
      "Saving data part73...\n",
      "Saving test data\n",
      "1080 to 1095\n",
      "Saving data part74...\n",
      "Saving test data\n",
      "1095 to 1110\n",
      "Saving data part75...\n",
      "Saving test data\n",
      "1110 to 1125\n",
      "Saving data part76...\n",
      "Saving test data\n",
      "1125 to 1140\n",
      "Saving data part77...\n",
      "Saving test data\n",
      "1140 to 1155\n",
      "Saving data part78...\n",
      "Saving test data\n",
      "1155 to 1170\n",
      "Saving data part79...\n",
      "Saving test data\n",
      "1170 to 1185\n",
      "Saving data part80...\n",
      "1185 to 1200\n",
      "Saving validation data...\n",
      "1200 to 1500\n"
     ]
    }
   ],
   "source": [
    "N=80\n",
    "num_test=20\n",
    "num_train=num_audios-num_test\n",
    "L=int(np.ceil(num_train/N)*num_slices)\n",
    "i=0\n",
    "for i in range(N):\n",
    "    if i<79:\n",
    "        print('Saving data part'+str(i+1)+'...')\n",
    "        print('Saving test data')\n",
    "        start=i*L\n",
    "        end=(i+1)*L\n",
    "        print(str(start)+' to '+str(end))\n",
    "#         print(video_input[start:end,1,1,1,1])\n",
    "#         print(audio_input[start:end,1,1])\n",
    "        sio.savemat(integrate_data_path+'preprocessed_data_final_part'+str(i+1)+'.mat', mdict={'video_input': video_input[start:end,:,:,:,:], 'audio_input' : audio_input[start:end,:,:]})\n",
    "    else:\n",
    "        print('Saving data part'+str(i+1)+'...')\n",
    "        start=i*L\n",
    "        end=num_train*num_slices\n",
    "        print(str(start)+' to '+str(end))\n",
    "#         print(video_input[start:end,1,1,1,1])\n",
    "#         print(audio_input[start:end,1,1])\n",
    "        sio.savemat(integrate_data_path+'preprocessed_data_final_part'+str(i+1)+'.mat', mdict={'video_input': video_input[start:end,:,:,:,:], 'audio_input' : audio_input[start:end,:,:]})\n",
    "\n",
    "print('Saving validation data...')\n",
    "start=num_train*num_slices\n",
    "print(str(start)+' to '+str(video_input.shape[0]))\n",
    "# print(video_input[start:,1,1,1,1])\n",
    "# print(audio_input[start:,1,1])\n",
    "sio.savemat(integrate_data_path+'preprocessed_data_final_validation.mat', mdict={'video_input': video_input[start:,:,:,:,:], 'audio_input' : audio_input[start:,:,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
